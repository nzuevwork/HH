# DevOps Homelab — Production-like Kubernetes инфраструктура с CI/CD и мониторингом

## О проекте

Это не учебный стенд Kubernetes.
Это постоянно работающая инфраструктура (24/7), на которой размещается веб-приложение с автоматическим деплоем, мониторингом и контролем доступности.

Цель проекта — моделирование реальной production-эксплуатации сервиса:

* обновления без простоя
* обнаружение и расследование инцидентов
* восстановление доступности
* Подробные разборы реальных сбоев инфраструктуры:
- /postmortems/2026-02-05-oom-crashloop.md
* предотвращение повторных падений

Я выступаю одновременно в роли **DevOps / SRE инженера**, отвечающего за доступность сервиса и работу инфраструктуры.

---

## Что размещено в кластере

В кластере постоянно работает веб-приложение, которое:

* автоматически деплоится при push в `main`
* доступно через ingress
* мониторится Prometheus
* имеет алерты и метрики
* проходит health-checks

---

## Архитектура

Инфраструктура разделена по ролям (как в реальной эксплуатации):

**1. Kubernetes cluster (k3s)**

* control-plane node
* worker node

**2. CI/CD сервер**

* self-hosted GitHub Actions runner
* сборка Docker-образов
* публикация в GitHub Container Registry

**3. Edge proxy**

* Nginx (внешняя точка входа)
* TLS termination

**4. Ingress**

* Traefik

**5. Monitoring**

* Prometheus
* node-exporter
* kube-state-metrics
* Grafana

---

## CI/CD Pipeline

Pipeline полностью автоматический.

При каждом `push` в `main` происходит:

1. Сборка Docker-образа
2. Публикация образа в GHCR
3. Обновление Deployment в Kubernetes
4. Rolling Update без остановки сервиса
5. Проверка readiness probes

Если деплой завершается ошибкой — выполняю диагностику и rollback.

---

## Kubernetes эксплуатация

В кластере используются:

* Deployments
* Services
* Ingress
* Secrets
* ConfigMaps
* readiness/liveness probes
* rolling updates

Я регулярно выполняю:

* диагностику `CrashLoopBackOff`
* анализ `OOMKilled`
* проверку сетевого взаимодействия сервисов
* анализ логов контейнеров
* обновление приложений без downtime

---

## Monitoring и наблюдаемость

Сервис находится под постоянным мониторингом.

Собираемые метрики:

**Инфраструктура**

* CPU
* RAM
* Disk
* network

**Kubernetes**

* состояние pod’ов
* рестарты контейнеров
* ресурсы namespace
* scheduler events

**Приложение**

* HTTP 4xx/5xx
* latency
* доступность ingress

Grafana используется для анализа деградаций и поиска причин инцидентов.

---

## Надёжность и эксплуатация

Я рассматриваю проект как эксплуатацию сервиса, а не просто развёртывание.

Цели:

* минимальный downtime
* обнаружение проблем до пользователя
* быстрое восстановление
* предотвращение повторных аварий

После каждого инцидента проводится анализ причин и внедряются изменения в конфигурацию или мониторинг.

---

## Пример инцидента (кратко)

Во время обновления приложения сервис начал возвращать 5xx ошибки.

Было выявлено:

* pod перезапускался
* контейнер завершался по OOMKilled

Действия:

* анализ логов контейнера
* проверка метрик памяти
* увеличение memory limits
* rolling restart

Результат:

* сервис восстановлен
* добавлен контроль потребления памяти
* настроены дополнительные алерты

(подробности в `/postmortems`)

---

## Что демонстрирует проект

Этот репозиторий показывает, что я умею:

* эксплуатировать Kubernetes, а не только разворачивать
* расследовать инциденты
* восстанавливать сервис
* работать с CI/CD
* наблюдать систему через метрики
* предотвращать повторные проблемы

---

## Используемые технологии

**Контейнеризация**

* Docker

**Оркестрация**

* Kubernetes (k3s)
* Traefik

**CI/CD**

* GitHub Actions (self-hosted runner)
* GHCR

**Наблюдаемость**

* Prometheus
* Grafana
* kube-state-metrics
* node-exporter

**Сеть**

* Nginx reverse proxy
* TLS

---

## Зачем этот проект

Проект создан как демонстрация навыков DevOps/SRE инженера:

* работа с production-подобной инфраструктурой
* ответственность за доступность
* эксплуатация сервиса 24/7
* практический опыт, а не лабораторные упражнения

---

## Контакты

GitHub: [https://github.com/nzuevwork](https://github.com/nzuevwork)
Email: [n.zuev.work@gmail.com](mailto:n.zuev.work@gmail.com)
